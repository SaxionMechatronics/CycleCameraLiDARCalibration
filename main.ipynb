{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR-thermal camera extrinsinc calibration\n",
    "## Data preparation\n",
    "\n",
    "The root folder should contain a folder with the lidar scans and a folder with the thermal images:\n",
    "- The LiDAR scans are saved as `.bin` files where we assume the data is arranged as `xyzi`. The file name of each scan is the timestamp.\n",
    "- Thermal images are 8-bit png files, where each image name is its timestamp.\n",
    "- A `timestamps.csv` should contain the LiDAR timestamps with corresponding thermal image timestamps. \n",
    "\n",
    "All intermediate results will be stored in the same root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Provide the paths below:\n",
    "root = \"/dataset\"\n",
    "camera_path = os.path.join(root, \"Boson\")\n",
    "lidar_path = os.path.join(root, \"Velodyne\")\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "timestamp_dict = {}\n",
    "time_diffs = []\n",
    "\n",
    "# Read the CSV file\n",
    "with open(os.path.join(root, 'timestamps.csv'), mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        value, key = row  # thermal camera timestamps used as key\n",
    "        timestamp_dict[key] = value\n",
    "        time_diffs.append(np.abs(float(key) - float(value)) *1e-6)\n",
    "\n",
    "N_stamps = len(timestamp_dict)\n",
    "mean_time_diff = np.mean(time_diffs)\n",
    "std_time_diff = np.std(time_diffs)\n",
    "print('Mean time difference:', mean_time_diff, 'ms')\n",
    "print('Std time difference:', std_time_diff, 'ms')\n",
    "\n",
    "inv_timestamp_dict = {} # lidar key, thermal value\n",
    "for key in timestamp_dict:\n",
    "    new_key = timestamp_dict[key]\n",
    "    inv_timestamp_dict[new_key] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Pattern Extraction and Thermal Pose Estimation\n",
    "### Prepare detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeT(Tmatrix):\n",
    "    \n",
    "    out = np.eye(4)\n",
    "    out[:3, :3] = Tmatrix[:3, :3].T\n",
    "    out[:3, 3] = -out[:3, :3].dot(Tmatrix[:3, 3])\n",
    "    \n",
    "    return out\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "Cmat = np.array([403.86291415, 0., 315.86709071, 0., 403.77831323, 249.0262173, 0.0, 0.0, 1.0]).reshape((3,-1))\n",
    "dist_coeffs = np.array([-0.38149332, 0.16357154, -0.00070473,  0.00065493, -0.03794994])\n",
    "print(Cmat)\n",
    "\n",
    "pattern_size = (4, 11) # Grid size of the calibration board\n",
    "\n",
    "params = cv2.SimpleBlobDetector_Params()   \n",
    "# Change thresholds\n",
    "params.minThreshold = 10 #50\n",
    "params.maxThreshold = 3000 #1500\n",
    "\n",
    "# Filter by Area\n",
    "params.filterByArea = True\n",
    "params.minArea = 1 #15\n",
    "params.maxArea = 5000\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.01\n",
    "params.maxCircularity = 30.0 #15.0\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.01\n",
    "params.maxConvexity = 30.0 #15.0\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the thermal images to estimate the 3D poses of the thermal camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid3D import *\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "headers = [\"timestamp\", \"angle [deg]\"] + [f\"T_thermal_w_{i}\" for i in range(16)]\n",
    "calib_data2D = []\n",
    "save_path_imgs = os.path.join(root, '2D_patterns')\n",
    "os.makedirs(save_path_imgs, exist_ok=True)\n",
    "save_path_points = os.path.join(root, '2D_points')\n",
    "os.makedirs(save_path_points, exist_ok=True)\n",
    "\n",
    "grid_pts3d = get_asymmetric_grid_3D(lidar_mode=True, flip_start_end=True) * 0.0424 \n",
    "# Add bottom_right corner:\n",
    "bottom_right = grid_pts3d[0,:] + np.array([0.0, 0.0629, -0.3535])\n",
    "# grid_pts3d = np.vstack([grid_pts3d, bottom_right])\n",
    "\n",
    "# Center around bottom right and make y positive to the left (in line with calibration board planes and Velodyne) \n",
    "\n",
    "grid_pts3d -= bottom_right\n",
    "grid_pts3d[:,1] *= -1.0\n",
    "np.savetxt(os.path.join(root, 'grid3D.csv'), grid_pts3d, fmt='%.4f', delimiter=',', header='x, y, z', comments='')\n",
    "\n",
    "# Threshold mask\n",
    "thr = 135\n",
    "\n",
    "T_rot_z_180 = np.array([[-1., 0., 0., 0.], [0., -1., 0., 0.,], [0., 0., 1., 0.], [0., 0., 0., 1.]]) # bring to world frame\n",
    "\n",
    "for i, key in enumerate(timestamp_dict):\n",
    "\n",
    "    img_file = key + '.png'\n",
    "    img = cv2.imread(os.path.join(camera_path, img_file),0)\n",
    "\n",
    "    _, mask = cv2.threshold(img, thr, 255, cv2.THRESH_BINARY_INV) #THRESH_BINARY_INV\n",
    "    found, centers = cv2.findCirclesGrid(mask, pattern_size, None, flags = (cv2.CALIB_CB_ASYMMETRIC_GRID + + cv2.CALIB_CB_CLUSTERING), blobDetector=detector)\n",
    "\n",
    "    disp_img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "    if found:\n",
    "        # Undistort 2D-grid\n",
    "        centers_u = cv2.undistortPoints(centers, Cmat, dist_coeffs)\n",
    "        centers_u = cv2.convertPointsToHomogeneous(centers_u) @ Cmat.T\n",
    "        centers_u = centers_u[:,0,:2]\n",
    "\n",
    "        # Compute 2D angle pattern\n",
    "        angle = np.arctan2(centers_u[0,1] - centers_u[-4,1], centers_u[0,0] - centers_u[-4,0]) / np.pi * 180.0\n",
    "\n",
    "        # Display results\n",
    "        disp_img = cv2.drawChessboardCorners(disp_img, pattern_size, centers, found)\n",
    "\n",
    "        # Compute 2D pose\n",
    "        _, rvec, tvec = cv2.solvePnP(grid_pts3d, centers, Cmat, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        R_thermal, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "        T_thermal = np.eye(4)\n",
    "        T_thermal[:3,:3] = R_thermal\n",
    "        T_thermal[:3,3] = tvec[:,0]\n",
    "        T_thermal_w = transposeT(T_thermal)\n",
    "\n",
    "        new_entry = [key, angle] + T_thermal_w.flatten().tolist()\n",
    "        calib_data2D.append(new_entry)\n",
    "        cv2.imwrite(os.path.join(save_path_imgs, img_file), disp_img)\n",
    "        \n",
    "        np.savetxt(os.path.join(save_path_points, key+'.csv'), centers_u, fmt='%.3f', delimiter=',', header='u, v', comments='')\n",
    "\n",
    "    progress = float(i) / float(N_stamps) * 100.0\n",
    "    print(\"Progress:\", progress)\n",
    "\n",
    "# Write to CSV\n",
    "with open(os.path.join(root,'poses2D.csv'), mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)  # Write headers\n",
    "    writer.writerows(calib_data2D)  # Write data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Planes extraction and LiDAR Pose Estimation\n",
    "### Function definitions for 3D LiDAR pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "from planeExtraction import *\n",
    "from planes3D_tools import *\n",
    "\n",
    "save_path_imgs_3D = os.path.join(root, '3D_planes')\n",
    "os.makedirs(save_path_imgs_3D, exist_ok=True)\n",
    "save_path_clouds = os.path.join(root, '3D_board_points')\n",
    "os.makedirs(save_path_clouds, exist_ok=True)    \n",
    "\n",
    "def get_orthonormal_rotation(Rmat):\n",
    "\n",
    "    # Step 1: SVD\n",
    "    U, _, Vt = np.linalg.svd(Rmat)\n",
    "\n",
    "    # Step 2: Compose corrected rotation matrix\n",
    "    R_fixed = U @ Vt\n",
    "\n",
    "    # Step 3: Ensure determinant is +1 (not -1 due to reflection)\n",
    "    if np.linalg.det(R_fixed) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R_fixed = U @ Vt\n",
    "\n",
    "    return R_fixed\n",
    "\n",
    "def extract_3d_board(stamp2D, angle2D):\n",
    "    \n",
    "    lidar_file = timestamp_dict[stamp2D] + '.bin'\n",
    "    lidar = np.fromfile(os.path.join(lidar_path, lidar_file), dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    points = lidar[:,:3]\n",
    "    points = prefilter_pointcloud(points, 45, 3.0)\n",
    "\n",
    "    points = RemoveNoiseStatistical(points, nb_neighbors=50, std_ratio=0.2)\n",
    "\n",
    "    results = DetectMultiPlanes(points, min_ratio=0.15, threshold=0.02, iterations=2000)\n",
    "    # # print('Time:', time.time() - t0)\n",
    "    planes = []\n",
    "    colors = []\n",
    "    plane_eqs = []\n",
    "    centers = []\n",
    "\n",
    "    for w, plane in results:\n",
    "\n",
    "        r = random.random()\n",
    "        g = random.random()\n",
    "        b = random.random()\n",
    "\n",
    "        color = np.zeros((plane.shape[0], plane.shape[1]))\n",
    "        color[:, 0] = r # 0.5\n",
    "        color[:, 1] = g # 0.5\n",
    "        color[:, 2] = b # 0.5\n",
    "            \n",
    "        planes.append(plane)\n",
    "        colors.append(color[:plane.shape[0],:])\n",
    "        plane_eqs.append(w)\n",
    "\n",
    "\n",
    "    # print(\"Detected {0} planes\".format(len(planes)))\n",
    "    if len(planes) < 3:\n",
    "        return []\n",
    "\n",
    "    closest_idxs = find_3_closest_planes(planes)\n",
    "    planes = [planes[i] for i in closest_idxs]\n",
    "    colors = [colors[i] for i in closest_idxs]\n",
    "    plane_eqs = [plane_eqs[i] for i in closest_idxs]\n",
    "\n",
    "    # Remove outlier planes:\n",
    "    skip_scan = False\n",
    "    for plane in planes:\n",
    "        # print(len(plane))\n",
    "        if len(plane) < 100:\n",
    "            # print(\"Skip this scan\")\n",
    "            skip_scan = True\n",
    "\n",
    "    if skip_scan:\n",
    "        return []\n",
    "\n",
    "    planes = np.concatenate(planes, axis=0)\n",
    "    new_planes, new_colors = refine_plane_boundaries(planes, plane_eqs)\n",
    "    for plane in new_planes:\n",
    "        center = np.mean(plane, axis=0)\n",
    "        centers.append(center)\n",
    "\n",
    "    board_center = np.mean(np.array(centers), axis=0)\n",
    "\n",
    "    new_planes = removeNoisePlanes(new_planes, centers, 0.35)\n",
    "\n",
    "    plane_order = find_plane_order(plane_eqs, centers)\n",
    "    if angle2D > 45.0:\n",
    "        plane_order = shift_to_left(plane_order)\n",
    "\n",
    "    # Rearrange in order target plane first\n",
    "    new_planes, new_colors, plane_eqs = reorder_planes(new_planes, plane_eqs, plane_order)\n",
    "\n",
    "    point12, line12 = plane_intersection(plane_eqs[0][:3], plane_eqs[0][3], plane_eqs[1][:3], plane_eqs[1][3])\n",
    "    point13, line13 = plane_intersection(plane_eqs[0][:3], plane_eqs[0][3], plane_eqs[2][:3], plane_eqs[2][3])\n",
    "    if line12[2]<0:\n",
    "        # Make the direction of this axis go from left to right according to the calibration pattern x-direction\n",
    "        line12 = -line12\n",
    "    if line13[1]<0:\n",
    "        # Make the direction of this axis go from right to left according to the calibration board planes\n",
    "        line13 = -line13\n",
    "\n",
    "    line12 = line12 / np.linalg.norm(line12)\n",
    "    line13 = line13 / np.linalg.norm(line13)\n",
    "\n",
    "    check_orthogonality = np.abs(np.dot(line12, line13))\n",
    "    # print('Orthogonality: ', check_orthogonailty)\n",
    "    if check_orthogonality > 1e-1:\n",
    "        # print(stamp2D, ': No orthogonal axes 12 and 13')\n",
    "        return []\n",
    "\n",
    "    line23 = np.cross(line12, line13)\n",
    "    if line23[0]<0:\n",
    "        # Make the direction of this axis go from left to right according to the calibration pattern x-direction\n",
    "        line23 = -line23\n",
    "\n",
    "    line23 = line23 / np.linalg.norm(line23)\n",
    "\n",
    "    intersection_pt = line_intersection(point12, line12, point13, line13)\n",
    "    if np.linalg.norm(intersection_pt - board_center) > 0.5:\n",
    "        return []\n",
    "\n",
    "    target_orientation = np.array([line23.T, line13.T, line12.T]).T\n",
    "    target_orientation_orthonormal = get_orthonormal_rotation(target_orientation)\n",
    "\n",
    "    T_lidar = np.eye(4)\n",
    "    T_lidar[:3,:3] = target_orientation_orthonormal\n",
    "    T_lidar[:3,3] = intersection_pt\n",
    "    T_lidar_w = transposeT(T_lidar)\n",
    "    new_entry = [timestamp_dict[stamp2D]] + T_lidar_w.flatten().tolist()\n",
    "\n",
    "    viz_line12 = viz_line_points(intersection_pt, line12, offset=0.75, dir_only=1)\n",
    "    viz_line13 = viz_line_points(intersection_pt, line13, offset=0.75, dir_only=1)\n",
    "    viz_line23 = viz_line_points(intersection_pt, line23, offset=0.75, dir_only=1) \n",
    "\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "    # Create a figure\n",
    "    fig = plt.figure(1)\n",
    "\n",
    "    # Add a 3D subplot\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for i in range(3):\n",
    "        # indices = np.random.choice(new_planes[i].shape[0], 1000, replace=False)\n",
    "        viz_pts = new_planes[i][:,:]\n",
    "        ax.scatter(viz_pts[:,0], viz_pts[:,1], viz_pts[:,2], c=colors[i])\n",
    "\n",
    "    ax.plot3D(viz_line12[:,0], viz_line12[:,1], viz_line12[:,2])\n",
    "    ax.plot3D(viz_line13[:,0], viz_line13[:,1], viz_line13[:,2])\n",
    "    ax.plot3D(viz_line23[:,0], viz_line23[:,1], viz_line23[:,2])\n",
    "    ax.scatter(intersection_pt[0], intersection_pt[1], intersection_pt[2], c='k', s=50)\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_xlabel('x [m]')\n",
    "    ax.set_ylabel('y [m]')\n",
    "    ax.set_zlabel('z [m]')\n",
    "\n",
    "    set_axes_equal(ax, set_limits=True, axis_limits=[[0.4, 2.6], [-1.5, 1.5], [-1.5, 0.8]])\n",
    "    ax.view_init(elev=45, azim=-180)\n",
    "\n",
    "    img_name = timestamp_dict[stamp2D] + '.png'\n",
    "    plt.savefig(os.path.join(save_path_imgs_3D, img_name), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    with open(os.path.join(save_path_clouds, timestamp_dict[stamp2D] + '.csv'), mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['x', 'y', 'z', 'plane'])\n",
    "        for i in range(3):\n",
    "            # for points in new_planes[i]:\n",
    "            points = new_planes[i]\n",
    "            for j in range(0,len(points), 5):\n",
    "                new_point = [points[j,0], points[j,1], points[j,2], i]\n",
    "                writer.writerow(new_point)\n",
    "\n",
    "    return new_entry\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the LiDAR scans to estimate the 3D poses of the LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers3D = [\"timestamp\"] + [f\"T_lidar_w_{i}\" for i in range(16)]\n",
    "calib_data3D = []\n",
    "\n",
    "patterns2D = np.genfromtxt(os.path.join(root, 'poses2D.csv'), delimiter=',', skip_header=1)\n",
    "stamps2D = patterns2D[:,0].astype(int).astype(str) # Only timestamp and angle for now\n",
    "angles2D = patterns2D[:,1]\n",
    "\n",
    "N_stamps = len(stamps2D)\n",
    "\n",
    "\n",
    "for i, stamp2d in enumerate(stamps2D):\n",
    "    pose3D = extract_3d_board(stamp2d, angles2D[i])\n",
    "    progress = float(i) / float(len(stamps2D)) * 100.0\n",
    "    print('Progress: ', progress)\n",
    "    if len(pose3D) > 0:\n",
    "        calib_data3D.append(pose3D)\n",
    "\n",
    "\n",
    "# Write to CSVs\n",
    "with open(os.path.join(root,'poses3D.csv'), mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers3D)  # Write headers\n",
    "    writer.writerows(calib_data3D)  # Write data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update camera pose list\n",
    "\n",
    "Only include camera poses that have a corresponding LiDAR pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lidar_stamps = np.genfromtxt(os.path.join(root, 'poses3D.csv'), delimiter=',', skip_header=1)[:,0].astype(int).astype(str)\n",
    "cam_poses = np.genfromtxt(os.path.join(root, 'poses2D.csv'), delimiter=',', skip_header=1)\n",
    "cam_stamps = cam_poses[:,0].astype(int).astype(str)\n",
    "\n",
    "update_cam_poses = []\n",
    "for i, cam_stamp in enumerate(cam_stamps):\n",
    "    query_lidar_stamp = timestamp_dict[cam_stamp]\n",
    "    if query_lidar_stamp in Lidar_stamps:\n",
    "        new_entry = [cam_stamp] + cam_poses[i,2:].tolist()\n",
    "        update_cam_poses.append(new_entry)\n",
    "    \n",
    "# Write to CSVs\n",
    "headers2D = [\"timestamp\"] + [f\"T_thermal_w_{i}\" for i in range(16)]\n",
    "with open(os.path.join(root,'poses2D_updated.csv'), mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers2D)  # Write headers\n",
    "    writer.writerows(update_cam_poses)  # Write data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual function\n",
    "\n",
    "Cycle constraint, linking camera poses, LiDAR poses (at two random timestamps) and the extrinsic transformation together (rigidity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "from jaxlie import SE3\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def transposeT_jax(Tmatrix):\n",
    "    \n",
    "    out = jnp.eye(4)\n",
    "    out = out.at[:3, :3].set(Tmatrix[:3, :3].T)\n",
    "    out = out.at[:3, 3].set(-out[:3, :3] @ Tmatrix[:3, 3])\n",
    "    \n",
    "    return out\n",
    "\n",
    "def rodrigues_to_matrix(r):\n",
    "    rot = R.from_rotvec(r)\n",
    "    return rot.as_matrix()\n",
    "\n",
    "def rodrigues_to_matrix_jax(r):\n",
    "    theta = jnp.linalg.norm(r)\n",
    "    def near_zero():\n",
    "        return jnp.eye(3)\n",
    "\n",
    "    def normal_case():\n",
    "        r_hat = r / theta\n",
    "        K = jnp.array([\n",
    "            [0, -r_hat[2], r_hat[1]],\n",
    "            [r_hat[2], 0, -r_hat[0]],\n",
    "            [-r_hat[1], r_hat[0], 0]\n",
    "        ])\n",
    "        return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)\n",
    "\n",
    "    return jax.lax.cond(theta < 1e-8, near_zero, normal_case)\n",
    "\n",
    "def matrix_to_rodrigues(Rmat):\n",
    "    rot = R.from_matrix(Rmat)\n",
    "    return rot.as_rotvec()\n",
    "\n",
    "def matrix_to_rodrigues_jax(Rmat):\n",
    "    trace = jnp.trace(Rmat)\n",
    "    cos_theta = (trace - 1.0) / 2.0\n",
    "    cos_theta = jnp.clip(cos_theta, -1.0, 1.0)\n",
    "    theta = jnp.arccos(cos_theta)\n",
    "\n",
    "    def near_zero():\n",
    "        return jnp.zeros(3)\n",
    "\n",
    "    def general_case():\n",
    "        denom = jnp.sin(theta) + 1e-8\n",
    "        skew_sym = (Rmat - Rmat.T) / (2.0 * denom)\n",
    "        return theta * jnp.array([\n",
    "            skew_sym[2,1],\n",
    "            skew_sym[0,2],\n",
    "            skew_sym[1,0]\n",
    "        ])\n",
    "\n",
    "    return jax.lax.cond(theta < 1e-6, near_zero, general_case)\n",
    "\n",
    "def cartesian_to_spherical_np(xyz):\n",
    "\n",
    "    r = np.sqrt(xyz[0]**2 + xyz[1]**2 + xyz[2]**2)\n",
    "    theta = np.arctan2(xyz[1], xyz[0])              # azimuthal angle\n",
    "    phi = np.arccos(xyz[2] / r) if r != 0 else 0  # polar angle\n",
    "\n",
    "    return np.array([r, theta, phi])\n",
    "\n",
    "def cartesian_to_spherical_jax(xyz):\n",
    "\n",
    "    r = jnp.sqrt(xyz[0]**2 + xyz[1]**2 + xyz[2]**2)\n",
    "    theta = jnp.arctan2(xyz[1], xyz[0]) # azimuthal angle\n",
    "    z_clamped = jnp.clip(xyz[2] / r, -1.0 + 1e-6, 1.0 - 1e-6)\n",
    "    phi = jnp.arccos(z_clamped)  # Polar angle\n",
    "    \n",
    "    return jnp.array([r, theta, phi])\n",
    "\n",
    "def spherical_to_cartesian_np(rtp):\n",
    "    \n",
    "    r, theta, phi = rtp\n",
    "\n",
    "    x = r * np.sin(phi) * np.cos(theta)\n",
    "    y = r * np.sin(phi) * np.sin(theta)\n",
    "    z = r * np.cos(phi)\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def spherical_to_cartesian_jax(rtp):\n",
    "\n",
    "    r, theta, phi = rtp\n",
    "    \n",
    "    x = r * jnp.sin(phi) * jnp.cos(theta)\n",
    "    y = r * jnp.sin(phi) * jnp.sin(theta)\n",
    "    z = r * jnp.cos(phi)\n",
    "\n",
    "    return jnp.array([x, y, z])\n",
    "\n",
    "def pose_vec_to_matrix_jax(pose_vec):\n",
    "    \n",
    "    out = jnp.eye(4)\n",
    "    out = out.at[:3,:3].set(rodrigues_to_matrix_jax(pose_vec[:3]))\n",
    "    out = out.at[:3,3].set(pose_vec[3:])\n",
    "    \n",
    "    return out\n",
    "\n",
    "def se3_log_jax(T):\n",
    "    return SE3.from_matrix(T).log()\n",
    "\n",
    "def cycle_constraint_residual(camera_pose1, camera_pose2, lidar_pose1, lidar_pose2, extrinsic, rot_weight=1.0, trans_weight=1.0):\n",
    "    \n",
    "    R_ex = rodrigues_to_matrix_jax(extrinsic[:3])\n",
    "    t_ex = extrinsic[3:] # spherical_to_cartesian_jax(extrinsic[3:])\n",
    "    \n",
    "    T_l_c = jnp.eye(4)\n",
    "    T_l_c = T_l_c.at[:3,:3].set(R_ex)\n",
    "    T_l_c = T_l_c.at[:3,3].set(t_ex)\n",
    "    T_c_l = transposeT_jax(T_l_c)\n",
    "\n",
    "    rel_pose_cam_1_2 = transposeT_jax(camera_pose2) @ camera_pose1\n",
    "    rel_pose_lidar_2_1 = transposeT_jax(lidar_pose1) @ lidar_pose2\n",
    "\n",
    "    res_mat =  rel_pose_lidar_2_1 @ (T_c_l @ (rel_pose_cam_1_2 @ T_l_c)) # If perfect extrinsinc calibration, this should return an Identity matrix\n",
    "\n",
    "    se3_vec = se3_log_jax(res_mat)\n",
    "\n",
    "    residual = rot_weight * jnp.linalg.norm(se3_vec[:3]) + trans_weight * jnp.linalg.norm(se3_vec[:3])\n",
    "    \n",
    "    return residual\n",
    "\n",
    "def make_total_cost_function_and_grad(cam_poses, lidar_poses, pair_idxs):\n",
    "\n",
    "    def total_cost_fn(x):\n",
    "        \n",
    "        x = jnp.array(x)\n",
    "        \n",
    "        batched_cycles = jax.vmap(cycle_constraint_residual, in_axes=(0, 0, 0, 0, None))\n",
    "        cycle_res = jnp.sum(batched_cycles(cam_poses, cam_poses[pair_idxs,:,:], lidar_poses, lidar_poses[pair_idxs,:,:], x))\n",
    "        \n",
    "        return cycle_res / cam_poses.shape[0]\n",
    "    \n",
    "    cost_fn_jit = jax.jit(total_cost_fn)\n",
    "    grad_fn_jit = jax.jit(jax.grad(total_cost_fn))\n",
    "\n",
    "    return cost_fn_jit, grad_fn_jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class ExtrinsicCalibrationOptimizer:\n",
    "    \n",
    "    def __init__(self, cam_poses, lidar_poses):\n",
    "        \n",
    "        # Camera parameters, detected 2d and 3D points of the calibration board\n",
    "        self.cam_poses = jnp.array(cam_poses)\n",
    "        \n",
    "        # LiDARs parameters, scans and point matches:\n",
    "        self.lidar_poses = jnp.array(lidar_poses)\n",
    "        \n",
    "        # Indices to extract the different sensor poses and extrinsic parameters from the 1-dimensional optimized parameter vector.\n",
    "        # First n_cam_poses * 6 parameters are camera poses, the next n_lidar_poses * 6 parameters are lidar poses and the final 6 parameters are the extrinsic parameters:\n",
    "        self.n_cam_poses = self.cam_poses.shape[0]\n",
    "        self.n_lidar_poses =  self.lidar_poses.shape[0]\n",
    "\n",
    "        self.pair_idxs = np.random.randint(0,self.n_cam_poses,self.n_cam_poses)\n",
    "\n",
    "    def evaluate(self, x):\n",
    "\n",
    "        cost_fn, grad_fn = make_total_cost_function_and_grad(self.cam_poses, self.lidar_poses)\n",
    "        print('Cost: ', cost_fn(x))\n",
    "        print('Grad: ', grad_fn(x))\n",
    "\n",
    "        \n",
    "    def estimate(self, init_extrinsic=np.zeros(6)):\n",
    "        \n",
    "        cost_fn, grad_fn = make_total_cost_function_and_grad(self.cam_poses, self.lidar_poses, self.pair_idxs)\n",
    "        \n",
    "        x0 = init_extrinsic \n",
    "        print('x0: ', x0)\n",
    "        \n",
    "        results = minimize(\n",
    "            fun=lambda x: float(cost_fn(x)),\n",
    "            x0=x0,\n",
    "            jac=lambda x: np.array(grad_fn(x)),\n",
    "            method='L-BFGS-B',\n",
    "            options={'disp': True,\n",
    "                     'ftol': 1e-12,\n",
    "                     'gtol':1e-12,\n",
    "                     'maxiter': 200}\n",
    "        )\n",
    "        \n",
    "        print(results)\n",
    "        final_extrinsic_vec = results.x\n",
    "        \n",
    "        return final_extrinsic_vec\n",
    "    \n",
    "    def evalutate_std_error(self, final_extrinsic=np.zeros(6)):\n",
    "        \n",
    "        T_l_c_diffs = []\n",
    "\n",
    "        T_l_c_final = np.eye(4)\n",
    "        T_l_c_final[:3,:3] = rodrigues_to_matrix(final_extrinsic[:3])\n",
    "        T_l_c_final[:3,3] = final_extrinsic[3:]\n",
    "\n",
    "        for i in range(self.n_cam_poses):\n",
    "            progress = float(i) / float(self.n_cam_poses) * 100.0\n",
    "            print(\"Progress: \", progress)\n",
    "\n",
    "            cost_fn, grad_fn = make_total_cost_function_and_grad(jnp.expand_dims(self.cam_poses[i], axis=0),\n",
    "                                                                 jnp.expand_dims(self.lidar_poses[i], axis=0), \n",
    "                                                                 jnp.expand_dims(self.pair_idxs[i], axis=0))\n",
    "        \n",
    "            x0 = final_extrinsic\n",
    "            \n",
    "            results = minimize(\n",
    "                fun=lambda x: float(cost_fn(x)),\n",
    "                x0=x0,\n",
    "                jac=lambda x: np.array(grad_fn(x)),\n",
    "                method='L-BFGS-B',\n",
    "                options={'disp': True,\n",
    "                        'ftol': 1e-12,\n",
    "                        'gtol':1e-12,\n",
    "                        'maxiter': 200}\n",
    "            )\n",
    "        \n",
    "            T_l_c_est = np.eye(4)\n",
    "            T_l_c_est[:3,:3] = rodrigues_to_matrix(results.x[:3])\n",
    "            T_l_c_est[:3,3] = results.x[3:]\n",
    "            T_l_c_diffs.append(T_l_c_final - T_l_c_est)\n",
    "\n",
    "        T_l_c_diffs_np = np.array(T_l_c_diffs)\n",
    "        sqrd_errors = T_l_c_diffs_np**2\n",
    "        sum_sqrd_errors = np.sum(sqrd_errors, axis=0)\n",
    "        std_error = np.sqrt(sum_sqrd_errors / T_l_c_diffs_np.shape[0]) / np.sqrt(T_l_c_diffs_np.shape[0])\n",
    "\n",
    "        print(std_error)\n",
    "        return std_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare observations for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_poses = np.genfromtxt(os.path.join(root, 'poses2D_updated.csv'), delimiter=',', skip_header=1)\n",
    "lidar_poses = np.genfromtxt(os.path.join(root, 'poses3D.csv'), delimiter=',', skip_header=1)\n",
    "\n",
    "cam_pose_mats = []\n",
    "lidar_pose_mats = []\n",
    "\n",
    "for i in range(cam_poses.shape[0]):\n",
    "    Tc = cam_poses[i,1:].reshape(4,4)\n",
    "    Tc[:3,3]\n",
    "    cam_pose_mats.append(Tc)\n",
    "\n",
    "    Tl = lidar_poses[i,1:].reshape(4,4)\n",
    "    Tl[:3,3]\n",
    "    lidar_pose_mats.append(Tl)\n",
    "\n",
    "cam_pose_mats = np.array(cam_pose_mats)\n",
    "lidar_pose_mats = np.array(lidar_pose_mats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ExtrinsicCalibrationOptimizer(cam_pose_mats, lidar_pose_mats)\n",
    "\n",
    "extrinsic_guess = np.array([1.20919958, -1.20919958,  1.20919958, 0.03, -.03, -0.077])\n",
    "\n",
    "final_extrinsic = optimizer.estimate(extrinsic_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the obtained extrinsic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_l_c_final = np.eye(4)\n",
    "T_l_c_final[:3,:3] = rodrigues_to_matrix(final_extrinsic[:3])\n",
    "T_l_c_final[:3,3] = final_extrinsic[3:]\n",
    "\n",
    "print('Final T_l_c:')\n",
    "print(np.array2string(T_l_c_final, precision=4, suppress_small=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Compute the deviation between the general solution and the solution to each pair of thermal-LiDAR measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ExtrinsicCalibrationOptimizer(cam_pose_mats, lidar_pose_mats)\n",
    "\n",
    "T_l_c_final = np.genfromtxt(os.path.join(root, 'Final_T_l_c.txt'))\n",
    "final_ext_vec = np.concatenate([matrix_to_rodrigues(T_l_c_final[:3,:3]), T_l_c_final[:3,3]])\n",
    "\n",
    "std_error = optimizer.evalutate_std_error(final_ext_vec)\n",
    "np.savetxt(os.path.join(root, 'std_error_extrinsics.txt'), std_error, fmt='%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "Project all LiDAR scans into their respective thermal image using the obtained extrinsic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import minimum_filter\n",
    "import time\n",
    "\n",
    "def projectToImg(points3D):\n",
    "\n",
    "    points2D = []\n",
    "    for pt3D in points3D:\n",
    "\n",
    "        if pt3D[2] < 0.3 or pt3D[2] > 10.0:\n",
    "            continue\n",
    "\n",
    "        u = np.round(Cmat[0,0] * pt3D[0] / pt3D[2] + Cmat[0,2])\n",
    "        v = np.round(Cmat[1,1] * pt3D[1] / pt3D[2] + Cmat[1,2])\n",
    "\n",
    "        if (u < 0) or (u >= 640) or (v < 0) or (v >= 512) or np.isnan(u) or np.isnan(v):\n",
    "            continue\n",
    "\n",
    "        points2D.append([u,v,pt3D[2]])\n",
    "\n",
    "    return np.array(points2D)\n",
    "\n",
    "def check_visibility(projected_points):\n",
    "    \n",
    "    depth_map = np.full((512, 640), np.inf)\n",
    "    visibility_mask = []\n",
    "    \n",
    "    for i, uvd in enumerate(projected_points):\n",
    "        u = np.round(uvd[0]).astype(int)\n",
    "        v = np.round(uvd[1]).astype(int)\n",
    "        depth = uvd[2]\n",
    "        if depth < depth_map[v,u]:\n",
    "            depth_map[v,u] = depth\n",
    "            \n",
    "    min_depth_neighborhood = minimum_filter(depth_map, size=20)\n",
    "    \n",
    "    for i, uvd in enumerate(projected_points):\n",
    "        u = np.round(uvd[0]).astype(int)\n",
    "        v = np.round(uvd[1]).astype(int)\n",
    "        depth = uvd[2]\n",
    "        if depth <= min_depth_neighborhood[v,u] + 0.1: # 0.1m depth tolerance\n",
    "            visibility_mask.append(True)\n",
    "        else:\n",
    "            visibility_mask.append(False)\n",
    "            \n",
    "    return np.array(visibility_mask)\n",
    "    \n",
    "def scalar_to_bgr(value):\n",
    "    # Ensure the value is within the range [0, 1]\n",
    "    value = max(0, min(1, value))\n",
    "\n",
    "    # Interpolate between the colors [1, 0, 0] (red) at value 0, [0, 1, 0] (green) at value 0.5, and [0, 0, 1] (blue) at value 1\n",
    "    if value < 0.5:\n",
    "        blue = 1 - 2 * value\n",
    "        green = 2 * value\n",
    "        red = 0\n",
    "    else:\n",
    "        blue = 0\n",
    "        green = 2 - 2 * value\n",
    "        red = 2 * (value - 0.5)\n",
    "    \n",
    "    # color = 255.0 * np.array([blue, green, red])\n",
    "    color = (int(255.0*blue), int(255.0*green), int(255.0*red))\n",
    "    return color\n",
    "\n",
    "\n",
    "T_l_c_final = np.genfromtxt(os.path.join(root, 'Final_T_l_c.txt'))\n",
    "\n",
    "save_path_proj_imgs = os.path.join(root, 'Projections')\n",
    "os.makedirs(save_path_proj_imgs, exist_ok=True)\n",
    "\n",
    "# Max and min depth value for visualization color scaling:\n",
    "maxDepth = 2.5\n",
    "minDepth = 0.3\n",
    "\n",
    "N_stamps = len(timestamp_dict)\n",
    "\n",
    "for i, key in enumerate(timestamp_dict):\n",
    "\n",
    "    img = cv2.imread(os.path.join(camera_path, key+'.png'),0)\n",
    "    lidar = np.fromfile(os.path.join(lidar_path, timestamp_dict[key]+'.bin'), dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    img_undist = cv2.undistort(img, Cmat, dist_coeffs, None, Cmat)\n",
    "    disp_img = cv2.cvtColor(img_undist,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    points3D_lidar = lidar[:,:3]\n",
    "    points3D_lidar_H = np.column_stack((points3D_lidar, np.ones(points3D_lidar.shape[0])))\n",
    "    points3D = (T_l_c_final @ points3D_lidar_H.T).T\n",
    "\n",
    "    points2D = projectToImg(points3D[:,:3])\n",
    "    visible_idxs = check_visibility(points2D)\n",
    "    visible_pts = points2D[visible_idxs,:]\n",
    "\n",
    "    for pt2D in visible_pts:\n",
    "\n",
    "        scalar = (pt2D[2] - minDepth) / (maxDepth - minDepth)\n",
    "        color = scalar_to_bgr(scalar)\n",
    "        center = tuple(pt2D[:2].astype(int))\n",
    "        disp_img = cv2.circle(disp_img, center, 2, color, -1)\n",
    "\n",
    "    save_name = key+'.png'\n",
    "    cv2.imwrite(os.path.join(save_path_proj_imgs, save_name), disp_img)\n",
    "\n",
    "    progress = float(i) / float(N_stamps) * 100\n",
    "    print('Progress:', progress)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimation evaluation using the obtained extrinsic transformation\n",
    "\n",
    "Compare observed LiDAR poses vs estimated LiDAR poses using thermal camera poses and the extrinsic transformation. Note that the error also contains noise and inconsistencies due to the computation of the pose observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getRMSE(diffs):\n",
    "\n",
    "    diffs_sqrd = diffs**2\n",
    "    return np.sqrt(np.mean(diffs_sqrd))\n",
    "\n",
    "T_l_c_final = np.genfromtxt(os.path.join(root, 'Final_T_l_c.txt'))\n",
    "T_c_l_final = transposeT(T_l_c_final)\n",
    "\n",
    "poses3D = np.genfromtxt(os.path.join(root, 'poses3D.csv'), delimiter=',', skip_header=1)\n",
    "poses2D = np.genfromtxt(os.path.join(root, 'poses2D.csv'), delimiter=',', skip_header=1)\n",
    "\n",
    "poses2D_dict = {}\n",
    "\n",
    "for pose2D in poses2D:\n",
    "    key = pose2D[0].astype(int).astype(str)\n",
    "    value = pose2D[2:].reshape(4,4)\n",
    "    poses2D_dict[key] = value\n",
    "\n",
    "errors = []\n",
    "N_t_below = 0\n",
    "err_angles = []\n",
    "diffs = []\n",
    "t_threshold = 0.15 #0.1\n",
    "r_threshold = 9.0 #7.0\n",
    "N_r_below = 0\n",
    "\n",
    "for i in range(len(poses3D)):\n",
    "    \n",
    "    timestamp3D = poses3D[i,0].astype(int).astype(str)\n",
    "    timestamp2D = inv_timestamp_dict[timestamp3D]\n",
    "\n",
    "    pose2D = poses2D_dict[timestamp2D]\n",
    "    pose3D = poses3D[i,1:].reshape(4,4)\n",
    "\n",
    "    est_pose3D = transposeT(T_c_l_final @ transposeT(pose2D))\n",
    "    diff_t = pose3D[:3,3] - est_pose3D[:3,3]\n",
    "    error_t = np.linalg.norm(diff_t)\n",
    "\n",
    "    # if error_t < 0.2:\n",
    "    errors.append(error_t)\n",
    "    diffs.append(diff_t)\n",
    "\n",
    "    if error_t < t_threshold:\n",
    "        N_t_below += 1\n",
    "\n",
    "    R_err = est_pose3D[:3,:3] @ pose3D[:3,:3].T\n",
    "    angle_error = np.arccos((np.trace(R_err) - 1) / 2) / np.pi * 180.0\n",
    "    # if angle_error < 10.0:\n",
    "    err_angles.append(angle_error)\n",
    "\n",
    "    if angle_error < r_threshold:\n",
    "        N_r_below += 1\n",
    "\n",
    "diffs = np.array(diffs)\n",
    "perc_t_below = float(N_t_below) / float(len(poses3D))\n",
    "rmse_t = getRMSE(diffs)\n",
    "rmse_t_per_axis = [getRMSE(diffs[:,0]), getRMSE(diffs[:,1]), getRMSE(diffs[:,2])]\n",
    "print('RMSE translation per axis:', rmse_t_per_axis, 'm')\n",
    "print('Percentage below threshold T:', perc_t_below)\n",
    "\n",
    "err_angles = np.array(err_angles)\n",
    "perc_r_below = float(N_r_below) / float(len(poses3D))\n",
    "rmse_r = getRMSE(err_angles)\n",
    "print('RMSE rotation:', rmse_r, 'deg')\n",
    "print('Percentage below threshold R:', perc_r_below)\n",
    "\n",
    "mean_e_t = np.mean(errors)\n",
    "mean_e_r = np.mean(err_angles)\n",
    "\n",
    "plt.figure(1)\n",
    "ax = plt.plot(range(len(errors)), errors, '-b', linewidth=3)\n",
    "plt.plot([0, len(errors)], [mean_e_t, mean_e_t], '--r', linewidth=3, label='Mean error = {:.4f} m'.format(mean_e_t))\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Error [m]')\n",
    "# plt.yscale('log')\n",
    "plt.title('Translational RMSE: {:.4f} m'.format(rmse_t))\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(root,'trans_error'))\n",
    "\n",
    "plt.figure(2)\n",
    "ax = plt.plot(range(len(err_angles)), err_angles, '-b', linewidth=3)\n",
    "plt.plot([0.0, len(err_angles)], [mean_e_r, mean_e_r], '--r', linewidth=3, label='Mean error = {:.3f} deg'.format(mean_e_r))\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Error [deg]')\n",
    "# plt.yscale('log')\n",
    "plt.title('Rotational RMSE: {:.2f} degrees'.format(rmse_r))\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(root,'rot_error'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_cuda12_scipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
